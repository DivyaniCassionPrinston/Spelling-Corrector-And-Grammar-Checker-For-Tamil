{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in /opt/anaconda3/lib/python3.12/site-packages (0.18.0)\n",
      "Collecting textblob\n",
      "  Using cached textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in /opt/anaconda3/lib/python3.12/site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.8->textblob) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.8->textblob) (4.66.5)\n",
      "Using cached textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n",
      "Collecting indic-nlp-library\n",
      "  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting sphinx-argparse (from indic-nlp-library)\n",
      "  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting sphinx-rtd-theme (from indic-nlp-library)\n",
      "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting morfessor (from indic-nlp-library)\n",
      "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from indic-nlp-library) (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from indic-nlp-library) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->indic-nlp-library) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->indic-nlp-library) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->indic-nlp-library) (2023.3)\n",
      "Requirement already satisfied: sphinx>=5.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx-argparse->indic-nlp-library) (7.3.7)\n",
      "Collecting docutils>=0.19 (from sphinx-argparse->indic-nlp-library)\n",
      "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n",
      "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.16.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.1.10)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.4)\n",
      "Requirement already satisfied: Pygments>=2.14 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.15.1)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.11.0)\n",
      "Requirement already satisfied: alabaster~=0.7.14 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (0.7.16)\n",
      "Requirement already satisfied: imagesize>=1.3 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.25.0 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.3)\n",
      "Requirement already satisfied: packaging>=21.0 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (24.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from Jinja2>=3.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.25.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.25.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.25.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.25.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2024.8.30)\n",
      "Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
      "Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
      "Downloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n",
      "Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
      "Installing collected packages: morfessor, docutils, sphinxcontrib-jquery, sphinx-argparse, sphinx-rtd-theme, indic-nlp-library\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.18.1\n",
      "    Uninstalling docutils-0.18.1:\n",
      "      Successfully uninstalled docutils-0.18.1\n",
      "Successfully installed docutils-0.21.2 indic-nlp-library-0.92 morfessor-2.0.6 sphinx-argparse-0.5.2 sphinx-rtd-theme-3.0.2 sphinxcontrib-jquery-4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy\n",
    "!pip install textblob\n",
    "!pip install indic-nlp-library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
    "\n",
    "def normalize_text(text):\n",
    "    normalizer = IndicNormalizerFactory().get_normalizer(\"ta\")\n",
    "    return normalizer.normalize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tamil_words(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        words = file.read().splitlines()\n",
    "    return set(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_misspellings(text, tamil_dict):\n",
    "    words = text.split()  # Simple word split\n",
    "    misspelled = [word for word in words if word not in tamil_dict]\n",
    "    return misspelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "def suggest_corrections(word, tamil_dict):\n",
    "    suggestions = process.extract(word, tamil_dict, limit=3)\n",
    "    return [suggestion[0] for suggestion in suggestions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tamil_spell_checker(text, wordlist_path):\n",
    "    tamil_dict = load_tamil_words(wordlist_path)\n",
    "    normalized_text = normalize_text(text)\n",
    "    misspelled = detect_misspellings(normalized_text, tamil_dict)\n",
    "    \n",
    "    corrections = {}\n",
    "    for word in misspelled:\n",
    "        corrections[word] = suggest_corrections(word, tamil_dict)\n",
    "    \n",
    "    return corrections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrections:\n",
      "தொழல்: தொழில், தேடல், வேலை\n",
      "\n",
      "Corrected Text:\n",
      "உங்களுடைய தொழில் என்ன\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
    "\n",
    "# Normalize Tamil text\n",
    "def normalize_text(text):\n",
    "    normalizer = IndicNormalizerFactory().get_normalizer(\"ta\")\n",
    "    return normalizer.normalize(text)\n",
    "\n",
    "# Load the Tamil dictionary\n",
    "def load_tamil_words(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        words = file.read().splitlines()\n",
    "    return set(words)\n",
    "\n",
    "# Detect misspelled words\n",
    "def detect_misspellings(text, tamil_dict):\n",
    "    words = text.split()  # Simple word split\n",
    "    misspelled = [word for word in words if word not in tamil_dict]\n",
    "    return misspelled\n",
    "\n",
    "# Suggest corrections\n",
    "def suggest_corrections(word, tamil_dict):\n",
    "    suggestions = process.extract(word, tamil_dict, limit=3)\n",
    "    return [suggestion[0] for suggestion in suggestions]\n",
    "\n",
    "# Spell checker with corrected text\n",
    "def tamil_spell_checker(text, wordlist_path):\n",
    "    tamil_dict = load_tamil_words(wordlist_path)\n",
    "    normalized_text = normalize_text(text)\n",
    "    words = normalized_text.split()\n",
    "    \n",
    "    # Detect misspellings and get corrections\n",
    "    misspelled = detect_misspellings(normalized_text, tamil_dict)\n",
    "    corrections = {}\n",
    "    corrected_words = []\n",
    "\n",
    "    for word in words:\n",
    "        if word in misspelled:\n",
    "            # Replace misspelled word with the top suggestion\n",
    "            top_correction = suggest_corrections(word, tamil_dict)[0]\n",
    "            corrections[word] = suggest_corrections(word, tamil_dict)\n",
    "            corrected_words.append(top_correction)\n",
    "        else:\n",
    "            corrected_words.append(word)\n",
    "    \n",
    "    # Join the corrected words into a full corrected text\n",
    "    corrected_text = ' '.join(corrected_words)\n",
    "    return corrections, corrected_text\n",
    "\n",
    "# Input text and wordlist path\n",
    "text = \"உங்களுடைய தொழல் என்ன\"\n",
    "wordlist_path = \"tamil_words.txt\"\n",
    "\n",
    "# Run the spell checker\n",
    "corrections, corrected_text = tamil_spell_checker(text, wordlist_path)\n",
    "\n",
    "# Output corrections and corrected text\n",
    "print(\"Corrections:\")\n",
    "for word, suggestions in corrections.items():\n",
    "    print(f\"{word}: {', '.join(suggestions)}\")\n",
    "\n",
    "print(\"\\nCorrected Text:\")\n",
    "print(corrected_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
