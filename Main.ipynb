{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Paragraph:\n",
      "உங்கள் நலமாக இருக்கிறேன்\n",
      "\n",
      "Corrected Paragraph:\n",
      "உங்கள் நலமாக இருக்கிறேன்\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from difflib import get_close_matches\n",
    "\n",
    "def load_correct_forms():\n",
    "    correct_forms = set()\n",
    "\n",
    "    ilakkanam_forms = [\n",
    "        \"அ\", \"ஆ\", \"இ\", \"ஈ\", \"உ\", \"ஊ\", \"எ\", \"ஏ\", \"ஐ\", \"ஒ\", \"ஓ\", \"ஔ\",\n",
    "        \"க்\", \"ச்\", \"ட்\", \"த்\", \"ப்\", \"ற்\",\n",
    "        \"ங்\", \"ஞ்\", \"ண்\", \"ந்\", \"ம்\", \"ன்\",\n",
    "        \"ய்\", \"ர்\", \"ல்\", \"வ்\", \"ழ்\", \"ள்\"\n",
    "    ]\n",
    "    correct_forms.update(ilakkanam_forms)\n",
    "\n",
    "    letters_forms = [\n",
    "        \"அ\", \"ஆ\", \"இ\", \"ஈ\", \"உ\", \"ஊ\", \"எ\", \"ஏ\", \"ஐ\", \"ஒ\", \"ஓ\", \"ஔ\",\n",
    "        \"க\", \"கா\", \"கி\", \"கீ\", \"கு\", \"கூ\", \"செ\", \"சே\", \"தை\", \"பூ\"\n",
    "    ]\n",
    "    correct_forms.update(letters_forms)\n",
    "\n",
    "    try:\n",
    "        with open(\"words.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "            words = file.read().splitlines()\n",
    "            correct_forms.update(words)\n",
    "    except FileNotFoundError:\n",
    "        print(\"words.txt not found. Make sure the file exists in the directory.\")\n",
    "\n",
    "    return correct_forms\n",
    "\n",
    "def tokenize_paragraph(paragraph):\n",
    "    tokens = re.split(r'\\s+|[.,;!?\"()]', paragraph)\n",
    "    return [token for token in tokens if token]\n",
    "\n",
    "def suggest_correction(word, correct_forms):\n",
    "    suggestions = get_close_matches(word, correct_forms, n=1, cutoff=0.7)\n",
    "    return suggestions[0] if suggestions else None\n",
    "\n",
    "def correct_paragraph(paragraph, correct_forms):\n",
    "    tokens = tokenize_paragraph(paragraph)\n",
    "    corrected_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if token in correct_forms:\n",
    "            corrected_tokens.append(token)  \n",
    "        else:\n",
    "            correction = suggest_correction(token, correct_forms)\n",
    "            corrected_tokens.append(correction if correction else token) \n",
    "\n",
    "    return \" \".join(corrected_tokens)\n",
    "\n",
    "def main():\n",
    "    correct_forms = load_correct_forms()\n",
    "    input_paragraph = \"உங்கள் நலமாக இருக்கிறேன்\"\n",
    "\n",
    "    print(\"Original Paragraph:\")\n",
    "    print(input_paragraph)\n",
    "\n",
    "    corrected_paragraph = correct_paragraph(input_paragraph, correct_forms)\n",
    "\n",
    "    print(\"\\nCorrected Paragraph:\")\n",
    "    print(corrected_paragraph)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Paragraph:\n",
      "உங்கள் நலமாக இருக்கிறேன்\n",
      "\n",
      "Corrected Paragraph:\n",
      "உங்கள் நலமாக இருக்கிறேன்\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
